{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "15a9621d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "aaaaa\n",
      "aaaaa\n",
      "aaaaa\n",
      "aaaaa\n",
      "aaaaa\n",
      "aaaaa\n",
      "aaaaa\n",
      "aaaaa\n",
      "aaaaa\n",
      "aaaaa\n",
      "asdasd\n",
      "asdasd\n",
      "asdasd\n",
      "asdasd\n",
      "asdasd\n",
      "asdasd\n",
      "asdasd\n",
      "asdasd\n",
      "asdasd\n",
      "asdasd\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, 'detection')\n",
    "from engine import train_one_epoch, evaluate\n",
    "import utils\n",
    "\n",
    "from CustomCocoDataset import CustomCocoDataset\n",
    "\n",
    "data_dir = 'data/laser_v3/'\n",
    "\n",
    "data_dir_images = data_dir + 'images'\n",
    "data_dir_annotations = data_dir + 'annotations/instances_default.json'\n",
    "\n",
    "def get_transform(train=None):\n",
    "    custom_transforms = []\n",
    "    custom_transforms.append(torchvision.transforms.ToTensor())\n",
    "    if train:\n",
    "        custom_transforms.append(torchvision.transforms.RandomHorizontalFlip())\n",
    "        custom_transforms.append(torchvision.transforms.RandomVerticalFlip())\n",
    "        #custom_transforms.append(torchvision.transforms.RandomPosterize())\n",
    "       # custom_transforms.append(torchvision.transforms.RandomSolarize())\n",
    "        custom_transforms.append(torchvision.transforms.RandomAdjustSharpness(2))\n",
    "        custom_transforms.append(torchvision.transforms.RandomAdjustSharpness(0))\n",
    "        custom_transforms.append(torchvision.transforms.RandomAutocontrast())\n",
    "        #custom_transforms.append(torchvision.transforms.RandomEqualize())\n",
    "    return torchvision.transforms.Compose(custom_transforms)\n",
    "\n",
    "\n",
    "dataset = CustomCocoDataset(root=data_dir_images,\n",
    "                          annotation=data_dir_annotations,\n",
    "                          transforms=get_transform(True)\n",
    "                          )\n",
    "dataset_val = CustomCocoDataset(root=data_dir_images,\n",
    "                          annotation=data_dir_annotations,\n",
    "                          transforms=get_transform(False)\n",
    "                          )\n",
    "dataset_test = CustomCocoDataset(root=data_dir_images,\n",
    "                          annotation=data_dir_annotations,\n",
    "                          transforms=get_transform(False)\n",
    "                          )\n",
    "\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "\n",
    "dataset_test = torch.utils.data.Subset(dataset_test, indices[-10:])\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(dataset_test, \n",
    "                                               batch_size=1, \n",
    "                                               shuffle=False, \n",
    "                                               num_workers=4,\n",
    "                                               collate_fn=utils.collate_fn)\n",
    "\n",
    "for images, image_ids in dataset_test:\n",
    "    print ('aaaaa')\n",
    "\n",
    "\n",
    "\n",
    "for images, image_ids in data_loader_test:\n",
    "    print ('asdasd')\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "620633e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#runfile('/home/tori/TelePhysicalOperation/src/tpo_vision/pytorchScripts/TestModel.py', wdir='/home/tori/TelePhysicalOperation/src/tpo_vision/pytorchScripts')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from ensemble_boxes import weighted_boxes_fusion\n",
    "\n",
    "detection_threshold = 0.5\n",
    "results = []\n",
    "outputs = []\n",
    "test_images = []\n",
    "\n",
    "def make_ensemble_predictions(images, models):\n",
    "    result = []\n",
    "    for net in models:\n",
    "        net.eval()\n",
    "        outputs = net(images)\n",
    "        result.append(outputs)\n",
    "    return result\n",
    "\n",
    "def run_wbf(predictions, image_index, image_size=1024, iou_thr=0.55, skip_box_thr=0.5, weights=None):\n",
    "    boxes = [prediction[image_index]['boxes'].data.cpu().numpy()/(image_size-1) for prediction in predictions]\n",
    "    scores = [prediction[image_index]['scores'].data.cpu().numpy() for prediction in predictions]\n",
    "    labels = [np.ones(prediction[image_index]['scores'].shape[0]) for prediction in predictions]\n",
    "    boxes, scores, labels = weighted_boxes_fusion(boxes, scores, labels, weights=None, iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n",
    "    boxes = boxes*(image_size-1)\n",
    "    return boxes, scores, labels\n",
    "\n",
    "def test(test_data_loader, models, device):\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for images, image_ids in test_data_loader:\n",
    "            images = list(image.to(device) for image in images)    \n",
    "            predictions = make_ensemble_predictions(images, models)\n",
    "        \n",
    "            for i, image in enumerate(images):\n",
    "                test_images.append(image) #Saving image values\n",
    "                boxes, scores, labels = run_wbf(predictions, image_index=i)\n",
    "        \n",
    "                boxes = boxes.astype(np.int32).clip(min=0, max=1023)\n",
    "                    \n",
    "                preds = boxes\n",
    "                preds_sorted_idx = np.argsort(scores)[::-1]\n",
    "                preds_sorted = preds[preds_sorted_idx]\n",
    "                boxes = preds\n",
    "                \n",
    "                output = {\n",
    "                    'boxes': boxes,\n",
    "                    'scores': scores\n",
    "                }\n",
    "\n",
    "        outputs.append(output) #Saving outputs and scores\n",
    "        image_id = image_ids[i]\n",
    "        \n",
    "        \n",
    "        ########### show images results\n",
    "        fig, axs = plt.subplots(2, 5, figsize=(32, 16))\n",
    "        axs = axs.ravel()\n",
    "        for i in range(10):\n",
    "            sample = test_images[i].permute(1,2,0).cpu().numpy()\n",
    "            boxes = outputs[i]['boxes']\n",
    "            scores = outputs[i]['scores']\n",
    "            boxes = boxes[scores >= detection_threshold].astype(np.int32)\n",
    "        \n",
    "            for box in boxes:\n",
    "                print(sample)\n",
    "                cv2.rectangle(sample,\n",
    "                              (box[0], box[1]),\n",
    "                              (box[2], box[3]),\n",
    "                              (220, 0, 0), 2)\n",
    "        \n",
    "            axs[i].set_axis_off()\n",
    "            axs[i].imshow(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "01ad95c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA not available, use CPU\n"
     ]
    }
   ],
   "source": [
    "###testing setup\n",
    "models = []\n",
    "\n",
    "model_path = 'model1.pt'\n",
    "model = None\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"CUDA available, use GPU\")\n",
    "    model = torch.load(model_path)\n",
    "\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"CUDA not available, use CPU\") \n",
    "    model = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a37b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "test(data_loader_test, models, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3976b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
